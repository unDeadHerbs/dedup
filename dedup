#! /usr/bin/env -S /bin/sh -c "exec \$(dirname \$(realpath "\$0"))/.virtualenv/bin/python -E "\$0" "\$@""
# Forgive the terrible shebang line, I didn't want to have to wrap this in a script, as the program is so short.
import os
import hashlib
import argparse
import re
from tqdm import tqdm

def find_duplicates(folder,pat):
    hash_map = {}
    duplicates = []

    patc = re.compile(pat)
    total_files = sum([1 for _, _, files in os.walk(folder) for f in files if patc.search(f)])
    pbar = tqdm(total=total_files, desc="Scanning  ", unit="file")
    
    for root, dirs, files in os.walk(folder):
        for file in files:
            file_path = os.path.join(root, file)
            if not patc.search(file_path): continue
            if os.path.isfile(file_path):
                with open(file_path, 'rb') as f:
                    file_hash = hashlib.sha256(f.read()).hexdigest()
                    if file_hash in hash_map:
                        duplicates[hash_map[file_hash]].append(file_path)
                    else:
                        hash_map[file_hash] = len(duplicates)
                        duplicates.append([file_path])
            pbar.update(1)
    pbar.close()
    return duplicates

def filter_files(file_list):
    # This function regularly modifies the list while iterating
    # through it.  This is safe here as the checks in the loop bodies
    # look at the updated state and the iterators moving though the
    # old list will never look at a deleted element.

    keep=file_list.copy()
    delete=[]

    def sub_each(pat, sub, s):
        """Generate a list of all possible strings obtained from
        replacing the pattern with the substitution in the input
        string (non-recursive).

        """
        patc=re.compile(pat)
        matches=patc.finditer(s)
        generated=[]
        for match in matches:
            if type(sub)==type(''):
                r=s[:match.start()] + sub + s[match.end():]
            else:
                r=s[:match.start()] + sub(match) + s[match.end():]
            generated.append(r)
        return generated
    
    def pattern_filter(pat,sub):
        for f in keep:
            patc = re.compile(pat)
            if patc.search(f):
                names_without = sub_each(pat,sub,f)
                for n in names_without:
                    if n in keep:
                        keep.remove(f)
                        delete.append((n,f))
                        break
    
    # If two files have the same name but one contains ' (n)', delete the one containing
    pattern_filter("[1-9][0-9]*",'')
    pattern_filter(" *[0-9]+",'')
    pattern_filter("[(][0-9]+[)]",'')
    pattern_filter(" +[(][0-9]+[)]",'')

    # If two files have the same name except for numbers, delete the larger number one (lexicographically later)
    for i in range(1,4):
        pattern_filter("[0-9]+",lambda n:str(int(n.group(0))-i))

    # If two files have the same name but one has less redundant spaces
    pattern_filter("  ",' ')

    # If one file has a name which is all numbers and another has one with text, delete the one with numbers
    all_nums = re.compile('[-0-9_., ]*$')
    for f in keep:
        base_name = ''.join(f.split('/')[-1].split('.')[:-1])
        if all_nums.match(base_name):
            for f2 in keep:
                base_name2 = ''.join(f2.split('/')[-1].split('.')[:-1])
                if not all_nums.match(base_name2):
                    keep.remove(f)
                    delete.append((f2,f))
                    break


    # If two have the same proper name but one is both in a sub directory and has an older date, remove newer
    # TODO: This date filter will expire in 2030, use the actual date to build this check.
    date = re.compile('(19[7-9]|20[012])[0-9][-_](0[1-9]|1[012])[-_](0[1-9]|[12][0-9]|3[0-1])')
    for f in keep:
        base_name = ''.join(f.split('/')[-1].split('.')[:-1])
        path = ''.join(f.split('/')[:-1])
        if date.search(base_name):
            # Using a dummy token to check that the dates are in the same place in both.
            name_no_date = date.sub('YDYD',base_name)
            for f2 in keep:
                if f==f2: continue # don't look at the same file
                n2 = ''.join(f2.split('/')[-1].split('.')[:-1])
                p2 = ''.join(f2.split('/')[:-1])
                # sub or same directory
                if p2.startswith(path):
                    nd2 = date.sub('YDYD',n2)
                    # same proper name
                    if name_no_date == nd2:
                        # is older or same
                        if n2 <= base_name:
                            keep.remove(f)
                            delete.append((f2,f))
                            break

    # TODO: If two files have the same name but one has more actual spaces
    # TODO: If two have the same proper name but one is both in a sub directory and has an older date, remove newer

    return (keep,delete)

def filter_groups(duplicates):
    count_dups = sum([len(d)>1 for d in duplicates])
    pbar = tqdm(total=count_dups, desc="Filtering ", unit="path")
    to_delete = []
    kept = []
    for duplicate_group in duplicates:
        if len(duplicate_group)>1:
            keep, delete = filter_files(duplicate_group)
            if len(delete) >= len(duplicate_group):
                print("WARNING: tried to delete everything, skipping")
                print("List of paths was:", delete)
                pbar.update(1)
                continue
            to_delete.extend(delete)
            kept.append(keep)
            pbar.update(1)
    pbar.close()
    return (kept,to_delete)

def delete_files(files):
    """
    Deletes a list of files.

    Args:
    - files (list): A list of file paths to delete.
    """
    pbar=tqdm(total=len(files), desc="Deleting  ", unit="path")
    for file_path in files:
        try:
            os.remove(file_path)
        except Exception as e:
            print(f"Failed to delete {file_path}: {e}")
        pbar.update(1)
    pbar.close()

def merge_names(files):
    """Take a set of file names and find new names that have more information packed into them.

    e.g. The two files `/a/date_c` and `/a/b/c` can become `/a/b/date_c`.
    """
    pass
    
def main():
    parser = argparse.ArgumentParser(description='Find and intelligently delete duplicate files in a folder.')
    parser.add_argument('pattern', nargs='?', default='', help='only look at files containing the pattern')
    parser.add_argument('folder', nargs='?', default=os.getcwd(), help='folder to search for duplicates (default: current directory)')
    args = parser.parse_args()

    folder = args.folder
    pat = args.pattern
    duplicates = find_duplicates(folder,pat)
    kept, to_delete = filter_groups(duplicates)
    if len(to_delete):
        delete_files([dell for keep,dell in to_delete])
        print("Removed",len(to_delete),"file(s)")
        for f in to_delete:
            print("-",f)
    else:
        print("Found no files to remove.")
    # TODO: Merge file information
    # if /path/date_1-name and /path/sub_path/date_2-name and date_2 is after date_1, move date_1 to the sub_path

if __name__ == "__main__":
    main()
